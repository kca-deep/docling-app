# =============================================================================
# Docling App Backend - Development Environment
# =============================================================================
# 개발 환경용 기본 설정 파일
#
# 사용 방법:
# 1. 이 파일을 .env로 복사: cp .env.example .env
# 2. 필요에 따라 서버 URL을 실제 서버 주소로 변경
#
# 프로덕션 배포 시: .env.production.example 참조
# =============================================================================

# =============================================================================
# 1. CORE APPLICATION (핵심 애플리케이션)
# =============================================================================
# 로그 및 통계에 사용할 타임존 (IANA timezone)
TIMEZONE=Asia/Seoul

# Database 설정
# SQLite (개발): sqlite:///./docling.db
# PostgreSQL (프로덕션): postgresql://user:password@localhost:5432/docling_db
DATABASE_URL=sqlite:///./docling.db

# API 정보
# FastAPI 문서에 표시될 제목과 버전
API_TITLE=Docling Parse API
API_VERSION=1.0.0

# =============================================================================
# 2. SECURITY & ACCESS (보안 및 접근 제어)
# =============================================================================
# 관리자 사용자명
ADMIN_USERNAME=admin

# 관리자 비밀번호
# [보안 경고] 기본값 'changeme'은 프로덕션에서 사용 금지!
# 반드시 강력한 비밀번호로 변경하세요 (대문자, 소문자, 숫자, 특수문자 포함)
ADMIN_PASSWORD=changeme

# JWT 토큰 서명에 사용할 비밀 키
# [보안 경고] 기본값 사용 시 서버 시작 실패!
# 반드시 랜덤한 긴 문자열(최소 32자)로 변경하세요
# 생성 방법: openssl rand -hex 32
SESSION_SECRET=your-secret-key-change-in-production

# 세션 만료 시간 (시간 단위)
SESSION_EXPIRE_HOURS=24

# CORS 설정
# 허용할 프론트엔드 도메인 (JSON 배열 형식)
# 프로덕션: ["https://yourdomain.com"]
ALLOWED_ORIGINS=["http://localhost:3000", "http://localhost:3001"]

# --- Rate Limiting 설정 ---
# Rate Limiting 활성화 여부
RATE_LIMIT_ENABLED=true

# 기본 요청 제한 (분당)
RATE_LIMIT_DEFAULT=100/minute

# 인증 엔드포인트 제한 (브루트포스 방지)
RATE_LIMIT_AUTH=5/minute

# 채팅 엔드포인트 제한 (LLM 비용 관리)
RATE_LIMIT_CHAT=30/minute

# 파일 업로드 제한
RATE_LIMIT_UPLOAD=10/minute

# 검색 엔드포인트 제한
RATE_LIMIT_SEARCH=60/minute

# Rate Limit 저장소 URI
# memory:// (개발), redis://localhost:6379 (프로덕션)
RATE_LIMIT_STORAGE_URI=memory://

# =============================================================================
# 3. HTTP & FILE (HTTP 클라이언트 및 파일 업로드)
# =============================================================================
# --- HTTP Client 설정 ---
# 최대 동시 연결 수
HTTP_MAX_CONNECTIONS=100

# Keep-Alive 연결 수
HTTP_MAX_KEEPALIVE=20

# 기본 타임아웃 (초)
HTTP_TIMEOUT_DEFAULT=30.0

# HTTP/2 사용 여부
HTTP_ENABLE_HTTP2=true

# --- 파일 업로드 설정 ---
# 최대 업로드 크기 (MB 단위) - 문서변환용
MAX_UPLOAD_SIZE_MB=50

# AI챗봇 파일 업로드 크기 제한 (MB 단위)
# VRAM 오버부킹 방지를 위해 3MB로 제한
CHAT_MAX_UPLOAD_SIZE_MB=3

# 허용할 파일 확장자 (JSON 배열 형식)
ALLOWED_EXTENSIONS=[".pdf", ".docx", ".doc", ".pptx", ".ppt"]

# =============================================================================
# 4. DOCUMENT PROCESSING (문서 처리)
# =============================================================================
# --- Docling Serve API 설정 ---
# 외부 Docling Serve API 서버 주소
DOCLING_BASE_URL=http://112.173.179.199:8007

# Docling Serve 청킹 API URL
# 기존 DOCLING_BASE_URL과 동일한 서버를 사용
DOCLING_CHUNKING_URL=http://112.173.179.199:8007

# Docling API 상태 확인 간격 (초)
POLL_INTERVAL=2

# --- Docling 동시성 제어 설정 (VRAM 최적화) ---
# 동시 Docling 요청 수 (VRAM 관리)
# 값이 낮을수록 VRAM 사용량 감소, 값이 높을수록 처리량 증가
# 권장값: 1-3 (GPU 메모리에 따라 조정)
DOCLING_CONCURRENCY=2

# 동시성 제어 활성화 (false면 무제한)
# VRAM 부족 문제 발생 시 true로 설정 권장
DOCLING_USE_SEMAPHORE=true

# 변환 완료 후 캐시 정리
# true: GPU 메모리 누수 방지를 위해 주기적으로 캐시 정리
DOCLING_CLEAR_CACHE_AFTER_CONVERT=true

# 캐시 정리 주기 (요청 수 기준, 0이면 매번)
# 0 = 매 변환마다 캐시 정리 (VRAM 즉시 회수, 권장)
DOCLING_CLEAR_CACHE_INTERVAL=0

# --- 청킹 기본 설정 ---
DEFAULT_CHUNK_SIZE=1000
DEFAULT_CHUNK_OVERLAP=200

# --- Qwen3 VL OCR 설정 (Docling 실패 시 폴백) ---
# Qwen3 VL API 서버 URL
QWEN3_VL_BASE_URL=http://112.173.179.199:8084

# Qwen3 VL 모델 이름
QWEN3_VL_MODEL=qwen3-vl-8b

# Qwen3 VL API 타임아웃 (초)
QWEN3_VL_TIMEOUT=120

# Qwen3 VL 최대 처리 페이지 수
QWEN3_VL_MAX_PAGES=50

# Qwen3 VL API 최대 토큰 수
QWEN3_VL_MAX_TOKENS=8192

# Qwen3 VL 온도 설정 (0.0 ~ 1.0)
QWEN3_VL_TEMPERATURE=0.1

# Qwen3 VL OCR 프롬프트 (텍스트 추출 지시)
QWEN3_VL_OCR_PROMPT="**KOREAN DOCUMENT OCR - UTF-8 ENCODING REQUIRED**

CRITICAL RULES (MUST FOLLOW):

1. **ENCODING**: Output in UTF-8 encoding. Preserve ALL Korean characters exactly.
   - Korean: 한글 (Hangul), 한자 (Hanja)
   - Special brackets: 「」『』〈〉《》
   - Circle numbers: ①②③④⑤⑥⑦⑧⑨⑩
   - Legal markers: <개정 2024.7.11.> [본조신설 2020.12.14.>

2. **EXTRACT EXACTLY**: Copy text character-by-character as shown in image.
   - DO NOT modify spacing, spelling, grammar, or formatting
   - Preserve ALL punctuation and special characters exactly
   - Keep original line breaks and paragraph structure

3. **PAGE ELEMENTS**:
   - EXCLUDE: Repeated headers/footers (page numbers, organization logos like \"KCA 한국방송통신전파진흥원\")
   - INCLUDE: All body content

4. **TABLES - CONDITIONAL**:
   - IF you see a table with rows and columns in the image, THEN use markdown table syntax:
     | Column1 | Column2 |
     | --- | --- |
     | Data1 | Data2 |
   - DO NOT create tables for plain numbered lists (1., 2., 3.)
   - DO NOT create tables for non-tabular content
   - Use <br> tag ONLY for line breaks inside table cells

5. **LEGAL DOCUMENTS** (if applicable):
   - Keep article numbers: 제1조, 제2조
   - Keep parentheses titles: (목적), (적용범위)
   - Keep amendment history: <개정 2024.7.11.>

6. **OUTPUT FORMAT**:
   - Plain markdown only
   - NO code blocks (\`\`\`)
   - NO examples from this prompt
   - DO NOT copy the table example above into the output

이미지의 모든 텍스트를 UTF-8 인코딩으로 정확히 추출하세요. 표가 실제로 있을 때만 마크다운 표 형식을 사용하고, 일반 목록은 원본 그대로 유지하세요. 프롬프트의 예시를 출력에 포함하지 마세요."

# =============================================================================
# 5. VECTOR PIPELINE (벡터 파이프라인)
# =============================================================================
# --- BGE-M3 임베딩 서버 설정 ---
# 임베딩 서버 URL
EMBEDDING_URL=http://112.173.179.199:8083

# 임베딩 모델 이름
EMBEDDING_MODEL=bge-m3-korean

# 임베딩 벡터 차원 (BGE-M3는 1024 고정)
EMBEDDING_DIMENSION=1024

# 임베딩 API Key (필요시)
# EMBEDDING_API_KEY=your_embedding_api_key_here

# --- Qdrant Vector DB 설정 ---
# Qdrant 서버 URL
QDRANT_URL=http://112.173.179.199:6333

# Qdrant API Key (필요시)
QDRANT_API_KEY=8bc1906404d5dd2bcbf076a3f14336060fa2f82c911ccf243fee2cd2ae515404

# 기본 Collection 이름
DEFAULT_COLLECTION_NAME=documents

# =============================================================================
# 6. SEARCH & RERANKING (검색 및 리랭킹)
# =============================================================================
# --- 하이브리드 검색 설정 (벡터 + BM25) ---
# 하이브리드 검색 활성화 여부
USE_HYBRID_SEARCH=true

# 벡터 검색 가중치 (0.0 ~ 1.0)
HYBRID_VECTOR_WEIGHT=0.7

# BM25 키워드 검색 가중치 (0.0 ~ 1.0)
HYBRID_BM25_WEIGHT=0.3

# RRF (Reciprocal Rank Fusion) 상수
# 값이 클수록 순위 차이의 영향이 줄어듦
HYBRID_RRF_K=60

# --- BGE Reranker v2-m3 설정 ---
# Reranker API 서버 URL
RERANKER_URL=http://112.173.179.199:8006

# Reranker 모델 이름
RERANKER_MODEL=BAAI/bge-reranker-v2-m3

# Reranker API 타임아웃 (초)
RERANKER_TIMEOUT=30

# Reranking 사용 여부
USE_RERANKING=True

# Reranking 시 초기 검색 배수 (top_k × multiplier개 검색 후 재정렬)
# 예: top_k=5, multiplier=3 → 15개 검색 → 재정렬 후 5개 선택
# 기존 5배에서 3배로 축소하여 속도 30% 향상
RERANK_TOP_K_MULTIPLIER=3

# Reranking 후 최소 관련도 점수 (0.0 ~ 1.0)
# BGE Reranker v2-m3의 실제 점수 분포: 관련 문서 0.2~0.5, 비관련 0.01 이하
RERANK_SCORE_THRESHOLD=0.2

# P0-1: 최소 답변 생성 임계값 (0.0 ~ 1.0)
# max_score가 이 값 미만이면 "관련 정보를 찾을 수 없습니다" 응답
# 할루시네이션 방지를 위해 너무 낮은 점수의 문서로 답변 생성 방지
MINIMUM_ANSWER_THRESHOLD=0.2

# =============================================================================
# 7. LLM MODELS (LLM 모델)
# =============================================================================
# --- 기본 LLM 설정 (GPT-OSS-20B) ---
# LLM 서버 URL
LLM_BASE_URL=http://112.173.179.199:8080

# LLM 모델 이름
LLM_MODEL=gpt-oss-20b

# LLM 기본 파라미터
LLM_DEFAULT_TEMPERATURE=0.7
LLM_DEFAULT_MAX_TOKENS=2000
LLM_DEFAULT_TOP_P=0.9

# LLM 컨텍스트 제한 설정
# RAG 전체 컨텍스트 최대 문자수 (약 4000~6000 토큰)
LLM_MAX_CONTEXT_CHARS=12000
# 개별 문서당 최대 문자수
LLM_MAX_DOC_CHARS=2000

# --- EXAONE Deep 7.8B 설정 (공식 권장값) ---
# 참고: https://github.com/LG-AI-EXAONE/EXAONE-Deep
EXAONE_DEEP_URL=http://112.173.179.199:8085
EXAONE_DEEP_MODEL=exaone-deep-7.8b
# EXAONE Deep 공식 권장 파라미터
EXAONE_DEEP_TEMPERATURE=0.6
EXAONE_DEEP_TOP_P=0.95
EXAONE_DEEP_MAX_TOKENS=8192
# repetition_penalty는 1.0 초과 금지 (공식 권장)
EXAONE_DEEP_REPETITION_PENALTY=1.0

# --- EXAONE 4.0 32B 설정 ---
EXAONE_4_0_32B_URL=http://112.173.179.199:8081
EXAONE_4_0_32B_MODEL=exaone-4.0-32b
EXAONE_4_0_32B_TEMPERATURE=0.7
EXAONE_4_0_32B_TOP_P=0.9
EXAONE_4_0_32B_MAX_TOKENS=8192

# =============================================================================
# 8. RAG & OPERATIONS (RAG 및 운영)
# =============================================================================
# --- RAG 설정 ---
# RAG 검색 기본 설정
RAG_DEFAULT_TOP_K=5

# 최소 유사도 점수 (벡터 검색 단계에서 필터링)
# BGE-M3 Cosine 유사도 기준, 0.4 이상만 검색
RAG_DEFAULT_SCORE_THRESHOLD=0.4

# 추론 수준 기본값 (low/medium/high)
RAG_DEFAULT_REASONING_LEVEL=medium

# 심층사고 활성화 시 추론 수준 (low/medium/high)
RAG_DEEP_THINKING_LEVEL=high

# 문서 선택 최소 스코어 임계값
DOCUMENT_SELECTOR_SCORE_THRESHOLD=0.3

# --- 프롬프트 자동 생성 설정 ---
# 시스템 프롬프트 생성 시 최대 출력 토큰
PROMPT_GEN_MAX_TOKENS=4096

# 추천 질문 생성 시 최대 출력 토큰
PROMPT_GEN_QUESTIONS_MAX_TOKENS=2000

# 문서 샘플 최대 문자수 (입력 토큰 절약용)
PROMPT_GEN_SAMPLE_LIMIT=3000

# --- 셀프진단 설정 ---
# 셀프진단 LLM 분석 최대 토큰 (10개 항목 JSON 응답용)
SELFCHECK_MAX_TOKENS=4000

# 개별 항목 분석 최대 토큰 (항목당 LLM 호출)
SELFCHECK_INDIVIDUAL_MAX_TOKENS=1000

# 종합의견 생성 최대 토큰
SELFCHECK_SUMMARY_MAX_TOKENS=500

# 셀프진단 LLM 온도 (일관성을 위해 낮게 설정)
SELFCHECK_TEMPERATURE=0.3

# 셀프진단 기본 신뢰도 값 (파싱 실패 시 기본값)
SELFCHECK_DEFAULT_CONFIDENCE=0.5

# 셀프진단 재시도 딜레이 (초)
SELFCHECK_RETRY_DELAY=0.5

# 셀프진단 최대 재시도 횟수
SELFCHECK_MAX_RETRIES=3

# --- 대화 로깅 및 히스토리 설정 ---
# 대화 샘플링 비율 (0.0 ~ 1.0)
# 1.0 = 100% 저장, 0.2 = 20% 샘플링
CONVERSATION_SAMPLE_RATE=1.0

# 대화 보존 기간 (일)
CONVERSATION_RETENTION_DAYS=30

# 대화 압축 정책 (일수)
# 이 기간이 지난 파일은 gzip으로 압축
CONVERSATION_COMPRESS_AFTER_DAYS=7

# 대화 품질 분류 임계값
# 낮은 검색 스코어 판정 임계값
CONVERSATION_LOW_SCORE_THRESHOLD=0.5
# 에러 수준 스코어 판정 임계값
CONVERSATION_ERROR_SCORE_THRESHOLD=0.3

# --- 임시 컬렉션 설정 (채팅 문서 업로드용) ---
# 임시 컬렉션 TTL (분)
# 이 시간이 지난 임시 컬렉션은 자동 삭제됨
TEMP_COLLECTION_TTL_MINUTES=15

# 임시 컬렉션 정리 스케줄러 실행 간격 (초)
TEMP_COLLECTION_CLEANUP_INTERVAL=300
