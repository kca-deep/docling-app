# CoP 최종 실적 보고서

> AI 기반 문서 자동화 및 RAG 시스템 구축

---

## 추진배경

### 1. 조직 지식자산 활용 극대화 필요

- KCA 통합 지식도메인 구축을 통한 RAG 기반 LLM 서비스 제공으로 업무 효율성 향상 필요
- 본사/지방 주니어 직원의 반복적인 규정 문의에 대한 시니어 담당자 업무 부담 증가
  - 동일한 질문에 대해 매번 개별 답변 필요
  - 규정집 검색 및 해석에 소요되는 시간 과다
  - 경험 기반 암묵지의 체계적 전달 부재

### 2. 업무망 전용 AI 인프라 구축 필요

- 외부 상용 AI 서비스(ChatGPT 등) 사용 시 내부 문서 유출 우려
  - 민감한 내부 규정 및 업무 자료의 외부 전송 위험
  - 정보보안 규정 준수 필요
- 업무망 내 폐쇄형 LLM 인프라 구축을 통한 보안성 확보
  - 모든 데이터의 내부 처리 보장
  - 외부 API 의존도 제거

### 3. 전문가 자문 및 연구활동 기반 구현

- LLM 모델 검토: LG EXAONE-3.5 Deep(32B/7B), OpenAI GPT-OSS(20B), NAVER CLOVA Studio(HCX-007)
- 업무망 환경에 최적화된 오픈소스 기반 서비스 설계
- RAG(Retrieval-Augmented Generation) 아키텍처 적용

---

## 추진내용

### 1. 도메인 지식 정비

#### 가. 문헌 정비
- 자격검정 업무 관련 제규정 등 26종 대상 도메인지식 구축
- 형식지와 암묵지 통합 관리 체계 수립
- PDF/A 방식 문서 표준화로 AI 데이터 추출 정확도 향상
  - AI 데이터추출 정확도가 높은 PDF/A 방식 문서 현행화 가이드라인 배포

#### 나. 수요 조사
- 본사/지방 주니어 대상 업무영역별 Q&A 템플릿 설문조사 실시
- 업무자동화 등 기능별 템플릿으로 수요 파악
- 현장에서 자주 발생하는 질문 및 업무상 어려움 수집

#### 다. 답변서 작성
- 시니어(KCAi 임피제) 검토를 통한 답변서 작성
- 사례/경험 등 실무중심 시니어 답변서 작성
- 답변 문서화, 메타데이터 생성 및 중복 검토
- 지식문서 구조화 및 태그 부여

### 2. 인프라 구축

#### 가. GPU 서버 구매
- 조달청 나라장터 종합쇼핑몰 GPU 서버 구매 추진
- 서버 사양
  - CPU: Intel Core Ultra 9 285K (24코어)
  - GPU: NVIDIA RTX 5090 32GB VRAM
  - RAM: 64GB DDR5
  - Storage: 2TB NVMe SSD
- 소요예산: 약 8백만원(VAT/조달수수료 포함)

#### 나. 보안성 검토
- KCA 업무망 내 구축에 따른 단계별 보안성 검토 추진
- 1차(자체): 전산장비 구매 목적 GPU 서버 도입 사전 보안성 검토 신청 및 승인 완료
- 2차(국정원): 서비스 업무망 적용 전 LLM 서비스 운영에 대한 종합 보안성 검토 추진 완료

#### 다. AI 서비스 구축

**LLM 추론 서버 (llama.cpp 기반):**

| 모델 | 역할 | VRAM | 설정 | 포트 |
|------|------|------|------|------|
| GPT-OSS 20B | 추론 특화 메인 LLM | ~16GB | ctx-size: 16384, parallel: 2 | 8080 |
| Qwen3-VL 8B | OCR/Vision 폴백 | ~12GB | ctx-size: 32768 | 8084 |

- llama.cpp 기반 추론 서버: GGUF 양자화 모델 사용
- KV Cache 관리: 컨텍스트 크기 및 병렬 처리 최적화
- OpenAI 호환 API: `/v1/chat/completions` 엔드포인트

**임베딩 및 재순위화:**

| 서비스 | 모델 | 차원/기능 | 포트 |
|--------|------|----------|------|
| BGE-M3 | bge-m3-korean | 1024차원 벡터 | 8083 |
| BGE Reranker v2-m3 | BAAI/bge-reranker-v2-m3 | Cross-encoder 재순위 | 8006 |

**문서 처리 및 저장:**

| 서비스 | 역할 | 포트 |
|--------|------|------|
| Docling Serve | PDF/DOCX/PPTX 파싱 → 마크다운 | 8007 |
| Qdrant | 벡터 데이터베이스 | 6333 |

### 3. 시스템 개발

#### 가. 전체 시스템 아키텍처

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                           KCA-i 시스템 아키텍처                               │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  ┌─────────────┐     ┌─────────────┐     ┌─────────────────────────────┐  │
│  │   사용자     │────▶│  Frontend   │────▶│         Backend            │  │
│  │  (업무망)    │◀────│ Next.js 16  │◀────│        FastAPI             │  │
│  └─────────────┘     └─────────────┘     └──────────────┬──────────────┘  │
│                             :3000                        │                 │
│                                                          │                 │
│  ┌───────────────────────────────────────────────────────┼─────────────┐  │
│  │                     AI 서비스 레이어                    │             │  │
│  │                                                       ▼             │  │
│  │  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐  ┌───────────┐  │  │
│  │  │ GPT-OSS 20B │  │ Qwen3-VL 8B │  │   BGE-M3    │  │ Reranker  │  │  │
│  │  │ (메인 LLM)  │  │ (OCR 폴백)  │  │ (임베딩)    │  │ (재순위)  │  │  │
│  │  │   :8080     │  │   :8084     │  │   :8083     │  │  :8006    │  │  │
│  │  └─────────────┘  └─────────────┘  └─────────────┘  └───────────┘  │  │
│  └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│  ┌─────────────────────────────────────────────────────────────────────┐  │
│  │                     데이터 레이어                                     │  │
│  │  ┌─────────────────┐              ┌─────────────────┐               │  │
│  │  │  Docling Serve  │              │     Qdrant      │               │  │
│  │  │  (문서 파싱)     │              │   (벡터 DB)     │               │  │
│  │  │     :8007       │              │     :6333       │               │  │
│  │  └─────────────────┘              └─────────────────┘               │  │
│  └─────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
│                          ┌─────────────┐                                   │
│                          │   SQLite    │                                   │
│                          │ (메타데이터) │                                   │
│                          └─────────────┘                                   │
└─────────────────────────────────────────────────────────────────────────────┘
```

#### 나. 문서 처리 워크플로우

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        문서 처리 파이프라인                                   │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  [1단계: 문서 업로드]                                                        │
│  ┌──────────┐                                                               │
│  │ PDF/DOCX │──▶ 파일 검증 (확장자, 크기 50MB 이하)                          │
│  │ PPTX     │                                                               │
│  └──────────┘                                                               │
│       │                                                                     │
│       ▼                                                                     │
│  [2단계: Docling 파싱] (비동기 3-Phase)                                      │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │ Phase 1: POST /v1/convert/file/async → task_id 발급                 │   │
│  │ Phase 2: GET /v1/status/poll/{task_id}?wait=2 → 완료까지 폴링       │   │
│  │ Phase 3: GET /v1/result/{task_id} → 마크다운 결과 수신              │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│       │                                                                     │
│       ├──[성공]──▶ 후처리 (표 복원, 섹션 감지, 페이지 추적)                  │
│       │                                                                     │
│       └──[실패/저품질]──▶ [3단계: Qwen3-VL OCR 폴백]                         │
│                          ┌─────────────────────────────────────────────┐   │
│                          │ PDF → 이미지 변환 (PyMuPDF)                 │   │
│                          │ 페이지별 Vision-Language 모델 OCR           │   │
│                          │ - temperature: 0.1 (정확도 우선)            │   │
│                          │ - max_tokens: 4096                          │   │
│                          │ 한글/표/서식 보존                           │   │
│                          └─────────────────────────────────────────────┘   │
│       │                                                                     │
│       ▼                                                                     │
│  [4단계: 청킹]                                                               │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │ Docling Chunking API 활용                                           │   │
│  │ - 시맨틱 청킹 (의미 단위 분할)                                       │   │
│  │ - chunk_size: 500 토큰 (기본값)                                      │   │
│  │ - overlap: 50 토큰                                                   │   │
│  │ - 계층적 구조 보존 (헤더, 섹션)                                      │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│       │                                                                     │
│       ▼                                                                     │
│  [5단계: 임베딩 생성]                                                        │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │ BGE-M3 모델 (bge-m3-korean)                                         │   │
│  │ - 1024차원 dense 벡터 생성                                           │   │
│  │ - 한국어 특화 임베딩                                                 │   │
│  │ - 배치 처리 지원                                                     │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│       │                                                                     │
│       ▼                                                                     │
│  [6단계: Qdrant 저장]                                                        │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │ 벡터 + 메타데이터 저장                                               │   │
│  │ - document_id, page_number, chunk_index                             │   │
│  │ - source (문서명), content (원문)                                    │   │
│  │ - Cosine similarity 거리 함수                                        │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

#### 다. RAG 질의응답 워크플로우

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        RAG 질의응답 파이프라인                                │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  [1단계: 사용자 질문 입력]                                                   │
│  ┌──────────────────────────────────────────────────────────────────────┐  │
│  │ 입력: 사용자 자연어 질문                                              │  │
│  │ 설정: 컬렉션 선택, 추론 레벨(low/medium/high), LLM 파라미터           │  │
│  └──────────────────────────────────────────────────────────────────────┘  │
│       │                                                                     │
│       ▼                                                                     │
│  [2단계: 쿼리 임베딩]                                                        │
│  ┌──────────────────────────────────────────────────────────────────────┐  │
│  │ BGE-M3: 질문 → 1024차원 벡터 변환                                     │  │
│  └──────────────────────────────────────────────────────────────────────┘  │
│       │                                                                     │
│       ▼                                                                     │
│  [3단계: 벡터 검색 (Qdrant)]                                                 │
│  ┌──────────────────────────────────────────────────────────────────────┐  │
│  │ 초기 검색: top_k × 5 (리랭킹용 후보 확보)                             │  │
│  │ - 기본 top_k: 5                                                       │  │
│  │ - score_threshold 적용 (선택)                                         │  │
│  │ - Cosine similarity 기반 유사도 계산                                  │  │
│  └──────────────────────────────────────────────────────────────────────┘  │
│       │                                                                     │
│       ▼                                                                     │
│  [4단계: Re-ranking] (USE_RERANKING=True인 경우)                             │
│  ┌──────────────────────────────────────────────────────────────────────┐  │
│  │ BGE Reranker v2-m3 (Cross-encoder)                                   │  │
│  │ - 쿼리-문서 쌍 관련성 점수 계산                                       │  │
│  │ - relevance_score 기반 재정렬                                         │  │
│  │ - RERANK_SCORE_THRESHOLD: 0.5 (기본값)                                │  │
│  │ - 최종 top_k 문서만 반환                                              │  │
│  └──────────────────────────────────────────────────────────────────────┘  │
│       │                                                                     │
│       ▼                                                                     │
│  [5단계: 프롬프트 구성]                                                      │
│  ┌──────────────────────────────────────────────────────────────────────┐  │
│  │ 시스템 프롬프트: backend/prompts/{collection_name}.txt 로드          │  │
│  │ 추론 레벨별 지시:                                                     │  │
│  │ - low: 간결하고 핵심만                                                │  │
│  │ - medium: 균형 잡힌 설명                                              │  │
│  │ - high: 상세 분석 + 추론 과정                                         │  │
│  │ 컨텍스트: 검색된 문서 내용 + 메타데이터                               │  │
│  │ 대화 이력: 멀티턴 컨텍스트 (선택)                                     │  │
│  └──────────────────────────────────────────────────────────────────────┘  │
│       │                                                                     │
│       ▼                                                                     │
│  [6단계: LLM 답변 생성]                                                      │
│  ┌──────────────────────────────────────────────────────────────────────┐  │
│  │ GPT-OSS 20B (llama.cpp 서버)                                         │  │
│  │ 파라미터:                                                             │  │
│  │ - temperature: 0.7 (기본값)                                           │  │
│  │ - max_tokens: 2000                                                    │  │
│  │ - top_p: 0.9                                                          │  │
│  │ 스트리밍: Server-Sent Events (SSE)                                    │  │
│  │ - 실시간 토큰 단위 전송                                               │  │
│  │ - 체감 응답 속도 향상                                                 │  │
│  └──────────────────────────────────────────────────────────────────────┘  │
│       │                                                                     │
│       ▼                                                                     │
│  [7단계: 응답 출력]                                                          │
│  ┌──────────────────────────────────────────────────────────────────────┐  │
│  │ 답변: LLM 생성 텍스트 (마크다운 형식)                                  │  │
│  │ 출처: 문서명, 페이지 번호, 유사도/관련성 점수                          │  │
│  │ 메타: 토큰 사용량 (usage)                                             │  │
│  └──────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

#### 라. 웹 애플리케이션 개발

**백엔드 (FastAPI + SQLite):**
- 총 47개 Python 모듈 (약 9,300 라인)
  - API 라우트: 8개 모듈 (document, qdrant, chat, dify, auth 등)
  - 서비스 레이어: 29개 모듈 (docling, qwen3, embedding, reranker, rag, llm 등)
  - 데이터 모델: 10개 모듈 (schemas, document, config 등)
- 비동기 HTTP 클라이언트: httpx.AsyncClient
- SQLAlchemy ORM 기반 데이터 영속화
- Rate Limiting: 100/분(기본), 30/분(채팅), 10/분(업로드)

**프론트엔드 (Next.js 16 + React 19):**
- 총 31개 TypeScript 모듈 (약 10,800 라인)
  - 페이지: 9개 (/, /parse, /url-parse, /qdrant, /chat, /dify 등)
  - UI 컴포넌트: 38개 (shadcn/ui 기반)
- App Router 아키텍처
- Server-Sent Events 기반 스트리밍
- react-hook-form + zod 폼 검증

**총 개발 코드량: 약 20,100 라인**

---

## 주요활동 실적

### 1. KCA-i AI 챗봇 시스템 구축 완료

**(가칭) KCA-i**: Knowledge & Certification Assistant - Intelligent (지능형 지식/자격 업무지원시스템)

#### 가. 시스템 개요
- 내부 업무망에 챗GPT 스타일의 RAG 기반 검색 서비스 구현
- 자연어를 통한 도메인지식 검색 기능 제공
- KCA AI 발굴 과제 및 CoP/부서별 파일럿 프로젝트 지원 플랫폼

#### 나. 운영 현황

| 컬렉션명 | 벡터 수 | 비고 |
|----------|--------|------|
| 인사 및 복무 | 189개 | 인사규정, 복무지침 등 |
| 예산관리 | 166개 | 예산편성, 집행지침 등 |
| 기금관리규정 | 182개 | 기금운용, 관리규정 등 |
| 자격검정(지식템플릿) | 182개 | 검정업무 Q&A, 매뉴얼 등 |
| ICT기금사업(100문100답) | 102개 | ICT기금 FAQ 등 |
| **총계** | **821개** | |

### 2. 핵심 기능 개발

#### 가. 문서 처리 기능
- **문서 파싱**: PDF, DOCX, PPTX → 마크다운 변환 (Docling 비동기 API)
  - 비동기 3-Phase 처리: Submit → Poll → Retrieve
  - 폴링 간격: 2초
- **OCR 폴백**: 이미지/스캔 PDF 처리 (Qwen3-VL Vision 모델)
  - Docling 파싱 실패 또는 품질 저하 시 자동 전환
  - PyMuPDF로 PDF → 이미지 변환
  - Vision-Language 모델로 텍스트 추출
  - 한글 문자, 표, 특수 서식 보존
- **표 구조 복원**: 마크다운 테이블 자동 생성
- **메타데이터 추출**: 페이지 번호, 섹션 정보, 문서 구조

#### 나. 검색 및 답변 기능
- **시맨틱 검색**: BGE-M3 1024차원 임베딩 기반 Cosine 유사도 검색
- **Re-ranking**: BGE Reranker v2-m3 Cross-encoder 통한 재순위화
  - 초기 검색 결과(top_k × 5) → 재순위화 → 최종 top_k 반환
  - 관련성 점수 임계값 적용 (기본 0.5)
- **출처 표시**: 문서명, 페이지 번호, 유사도 점수 제공
- **추론 레벨**: low(간결) / medium(균형) / high(상세) 선택 가능

#### 다. 사용자 인터페이스
- **스트리밍 채팅**: Server-Sent Events 기반 실시간 답변 표시
- **대화 이력 관리**: 멀티턴 대화 컨텍스트 유지
- **답변 재생성**: 동일 검색 결과로 다른 파라미터 적용 가능
- **다크 모드**: next-themes 기반 테마 전환

### 3. LLM 모델 및 서비스 구성

#### 가. 메인 LLM: GPT-OSS 20B
- **역할**: 추론 특화 대화 생성
- **구동 방식**: llama.cpp 서버 (GGUF Q4_K_M 양자화)
- **설정**:
  - ctx-size: 16,384 토큰
  - parallel: 2 (동시 요청)
  - VRAM 사용량: ~16GB
- **API**: OpenAI 호환 `/v1/chat/completions`

#### 나. OCR 폴백: Qwen3-VL 8B
- **역할**: Vision-Language 기반 OCR
- **구동 방식**: llama.cpp 서버 (GGUF 양자화)
- **설정**:
  - ctx-size: 32,768 토큰
  - temperature: 0.1 (정확도 우선)
  - max_tokens: 4,096
  - VRAM 사용량: ~12GB

#### 다. 임베딩: BGE-M3
- **역할**: 텍스트 → 벡터 변환
- **모델**: bge-m3-korean (한국어 특화)
- **출력**: 1024차원 dense 벡터
- **VRAM 사용량**: <1GB

#### 라. 리랭커: BGE Reranker v2-m3
- **역할**: 검색 결과 정확도 향상
- **방식**: Cross-encoder 기반 쿼리-문서 관련성 점수
- **VRAM 사용량**: 1-2GB

### 4. 학습 및 연구 활동

#### 가. RAG 아키텍처
- 벡터 DB 설계 및 운영 (Qdrant)
- 임베딩 모델 선정 및 적용 (BGE-M3)
- 리랭킹 파이프라인 구축 (BGE Reranker v2-m3)
- 청킹 전략 수립 (시맨틱 청킹, 오버랩 설정)

#### 나. LLM 추론 최적화
- llama.cpp 기반 추론 서버 구축
- GGUF 양자화 모델 활용 (Q4_K_M, Q5_K_M)
- KV Cache 관리 및 컨텍스트 크기 최적화
- 병렬 요청 처리 설정

#### 다. 풀스택 개발
- 백엔드: FastAPI 비동기 프로그래밍, SQLAlchemy ORM
- 프론트엔드: Next.js 16 App Router, React 19
- 프롬프트 엔지니어링: System prompt 설계, Reasoning level 조정

---

## 추진성과 및 기대효과

### 1. 정량적 성과

| 지표 | 성과 | 비고 |
|------|------|------|
| 벡터 데이터 | 821개 청크 | 5개 컬렉션 |
| 문서 처리 속도 | 평균 3초/문서 | 업로드~벡터 저장 |
| 벡터 차원 | 1024차원 | BGE-M3 |
| 동시 처리 | 2~8개 요청 | 병렬 처리 |
| 개발 코드량 | 약 20,100 라인 | Python + TypeScript |
| 백엔드 모듈 | 47개 | 서비스/API/모델 |
| 프론트엔드 페이지 | 9개 | Next.js App Router |
| UI 컴포넌트 | 38개 | shadcn/ui 기반 |
| 시스템 가용성 | 24/7 | Systemd 서비스 등록 |

### 2. 정성적 성과

#### 가. 업무 효율성 향상
- 챗GPT 스타일의 RAG 검색으로 규정 문의 자동화
- 주니어 직원의 시니어 의존도 감소
- 반복 질문에 대한 즉시 응답 가능

#### 나. 정보 접근성 개선
- 자연어 질의로 복잡한 규정 즉시 검색
- 출처 기반 답변으로 신뢰성 확보
- 규정집 수동 검색 시간 대폭 단축

#### 다. AI 역량 내재화
- RAG, LLM, Vector DB, Reranking 등 최신 AI 기술 실무 적용 경험 축적
- 외주 의존 없이 자체 AI 시스템 구축/운영 역량 확보
- 오픈소스 기반 기술 스택 활용 능력 배양

#### 라. 보안성 확보
- 업무망 내부 서버 운영으로 데이터 유출 방지
- 외부 상용 AI 서비스 미사용
- 폐쇄형 시스템으로 정보보안 규정 준수

### 3. 기대효과

#### 가. 확장성
- 추가 문서 업로드만으로 지식베이스 즉시 확장
- 새로운 규정/업무 자료 추가 시 별도 개발 불필요
- 컬렉션 단위 도메인 분리 관리

#### 나. 재사용성
- 타 부서/업무영역 도메인지식 확산을 위한 참조 모델
- 동일 아키텍처의 다른 업무 영역 적용 가능
- 조직 전체 지식 관리 효율 향상

#### 다. 비용 효율
- 상용 AI SaaS 대비 자체 운영으로 장기 비용 절감
- 초기 투자(약 8백만원) 이후 추가 비용 최소화
- API 호출 비용 없음

#### 라. 데이터 주권
- 폐쇄형 시스템으로 내부 문서 외부 유출 원천 방지
- 모든 데이터 업무망 내부 처리
- 정보보안 규정 완전 준수

---

## 향후계획

### 1. 단기 계획 (2025년 내)

#### 가. 도메인 마이그레이션
- 현재: ai.kca.kr (공식 도메인)
- 목표: ai.kca.kr (공식 도메인)
- KICA SSL 인증서 적용으로 보안성 강화
- 공식 도메인 사용으로 서비스 신뢰도 향상

#### 나. 사용자 확대
- 파일럿 부서 확대 적용
- 사용자 피드백 수집 및 반영
- 사용성 개선 및 UI/UX 고도화

#### 다. 컬렉션 추가
- 현재 5개 → 타 업무영역 확장
- 대상: 회계, 계약, 인사, 총무 등
- 조직 전체 지식 통합 관리 플랫폼화

#### 라. 모니터링 강화
- 사용 통계 대시보드 고도화
- 자주 묻는 질문 분석
- 응답 품질 모니터링
- 시스템 사용량 추적

### 2. 중장기 계획 (2026년)

#### 가. 멀티모달 확장
- 이미지, 표 데이터 직접 질의 기능 추가
- 문서 내 도표/그래프에 대한 자연어 질문 지원
- Vision-Language 모델 고도화

#### 나. 대화 분석
- 자주 묻는 질문 분석 → FAQ 자동 생성
- 반복 질문 패턴 파악
- 선제적 정보 제공 기능

#### 다. 타 시스템 연계
- 전자결재 시스템 연동
- 그룹웨어 통합
- 업무 흐름 내 자연스러운 AI 지원

#### 라. 성과 공유
- 기관 내 AI 활용 우수사례 공유
- 교육 자료화
- 조직 전체 AI 활용 역량 강화

---

**문서 작성일**: 2025-12-09
